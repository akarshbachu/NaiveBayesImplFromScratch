{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Implementation from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes is most commonly used for Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import sqlite3\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    \"\"\"\n",
    "    This class contains four methods:\n",
    "    1. def addSentToBow(self,example_sentence,bow_dict_index)\n",
    "    2. def train(self,X,y):\n",
    "    3. def getPosteriorProba(self,test_sent)\n",
    "    4. def test(self,test_data)\n",
    "    \n",
    "    Through these 4 methods we can train a Naive Bayes Classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,unique_labels):\n",
    "        self.classes = unique_labels\n",
    "    \n",
    "    def addSentToBow(self,example_sentence,bow_dict_index):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        -> example_sentance : is the sentence we pass to test/train\n",
    "        -> bow_dict_index : or class is a dict to which our example_sent belongs to\n",
    "        i.e if we have two classes then we will maintain 2 bow dicts\n",
    "        \n",
    "        \n",
    "        Functionality:\n",
    "        --------------\n",
    "        It will tokenize the sentence and adds every token to its respective\n",
    "        BOW dict(label parameter in here)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        #checking if example sent is of type nd array i.e array([]) and getting the sentence\n",
    "        if(isinstance(example_sentence,np.ndarray)):\n",
    "            example_sentence = example_sentence[0]\n",
    "        \n",
    "        \n",
    "        for word in example_sentence.split():\n",
    "            '''\n",
    "                Creating BOW dict:\n",
    "                {\n",
    "                    class1:{\n",
    "                        word1:count,\n",
    "                        word2:count\n",
    "                    }\n",
    "                    class2:{\n",
    "                        word1:count,\n",
    "                        word2:count\n",
    "                    }\n",
    "                }\n",
    "            '''\n",
    "            self.bow_label_dict[bow_dict_index][word]+=1\n",
    "            \n",
    "    \n",
    "    def train(self,X,y):\n",
    "        \"\"\"\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        \n",
    "        1. X \n",
    "        2. y i.e target labels\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = X\n",
    "        self.labels=y\n",
    "        # Creating dict of n dicts, where n is no.of classes\n",
    "        self.bow_label_dict = np.array([defaultdict(lambda:0) for index in range(self.classes.shape[0])])\n",
    "        \n",
    "        # converting data to numpy arrays\n",
    "        if not isinstance(self.data,np.ndarray): \n",
    "            self.data=np.array(self.data)\n",
    "        if not isinstance(self.labels,np.ndarray): \n",
    "            self.labels=np.array(self.labels)\n",
    "        \n",
    "        #Creating BOW for each Class\n",
    "        \n",
    "        #enumerate method will return tuple (counter,element in collection)\n",
    "        # here if we have 3 classes it will return (0,1),(1,2),(2,3)\n",
    "        for index,label in enumerate(self.classes):\n",
    "            \n",
    "            sentOfParticularLabel = self.data[self.labels==label]\n",
    "            \n",
    "            cleaned_sent = [preprocess_string(sent) for sent in sentOfParticularLabel]\n",
    "            cleaned_sent=pd.DataFrame(data=cleaned_sent)\n",
    "            \n",
    "            #now costruct BoW of this particular label\n",
    "            '''\n",
    "            -> addSentToBow is method\n",
    "            -> 1 -> indicates axis i.e Column\n",
    "            -> cleaned_sent - is a Data frame where column values are sentences\n",
    "            -> index - param accepted by addSentToBow method\n",
    "            \n",
    "            here we have only two cols one is index col and other is Sentences column\n",
    "            now operation is performed on sentence column\n",
    "            '''\n",
    "            \n",
    "            np.apply_along_axis(self.addSentToBow,1,cleaned_sent,index)\n",
    "            \n",
    "            '''\n",
    "            Done with constructing BOW of each Label/category.\n",
    "            \n",
    "            Now we need calculate the terms of our formula:\n",
    "            \n",
    "            -> Prior Probability of each class - P(c) -> (no.of sentences beloning to class c)/(total no.of sent)\n",
    "            -> Word Corpus/ Vocabulary |V|\n",
    "            -> count(c) + |v| + 1 i.e denominator val of each label/class\n",
    "            \n",
    "            'c' here is Class/label\n",
    "            '''\n",
    "            \n",
    "            \n",
    "        # Creating a array to store the probability of \n",
    "        # of sentence for each class\n",
    "        proba_label = np.empty(self.classes.shape[0])\n",
    "            \n",
    "        all_words = []\n",
    "            \n",
    "        count_of_words_in_each_class = np.empty(self.classes.shape[0])\n",
    "            \n",
    "        for index, label in enumerate(self.classes):\n",
    "            \n",
    "            #Prior probability P(c) for each class\n",
    "            '''\n",
    "            labels-> target column values i.e y\n",
    "            label -> one of the selected label for this iteration\n",
    "            '''\n",
    "            proba_label[index] = np.sum(self.labels==label)/float(self.labels.shape[0])\n",
    "            \n",
    "            # getting total counts of all words in each class\n",
    "            count = list(self.bow_label_dict[index].values())\n",
    "            \n",
    "            count_of_words_in_each_class[index] = np.sum(np.array(count))+1\n",
    "            \n",
    "            all_words+=self.bow_label_dict[index].keys()\n",
    "            \n",
    "        # now combining all the words of all the classes to get |V|\n",
    "        self.vocab = np.unique(np.array(all_words))\n",
    "        \n",
    "        self.lenOfVocab = self.vocab.shape[0]\n",
    "        \n",
    "        #Computing denominators of each class i.e (count(c) + |v| + 1) i.e\n",
    "        # count of words of that class + Vocab|v|(adding this to avoide 0 probability \n",
    "        # when word is unknown)+1\n",
    "        denom = np.array([count_of_words_in_each_class[index]+self.lenOfVocab+1 for index,label in enumerate(self.classes)])\n",
    "        \n",
    "        \n",
    "        # putting pieces of formula in organized way\n",
    "        # in this way (bow dict of each class,prior probability,denominator)\n",
    "        self.classes_info = [(self.bow_label_dict[index],proba_label[index],denom[index]) for index,labels in enumerate(self.classes)]\n",
    "        self.classes_info = np.array(self.classes_info)\n",
    "    \n",
    "    \n",
    "    def getPosteriorProba(self,test_sent):\n",
    "        '''\n",
    "        Parameter:\n",
    "        ----------\n",
    "        test_example -> Example sentence \n",
    "        \n",
    "        -> This function returns Posterior probability of given sentence\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        Probability that belongs to each class\n",
    "        \n",
    "        '''\n",
    "        # To store probabilities of each class\n",
    "        likelihood_prob = np.zeros(self.classes.shape[0])\n",
    "        \n",
    "        # Calculating Probabilities w.r.t to each label/class\n",
    "        # Formula -> (count of word w.r.t class c +1)/(count wof words in that class + vocab_len + 1)\n",
    "        for index,labels in enumerate(self.classes):\n",
    "            \n",
    "            for word in test_sent.split():\n",
    "                \n",
    "                # numerator in the above formula\n",
    "                # adding +1 to get rid of zero probability i.e even when the word is not present in our training vocab\n",
    "                # then also probability will not be zero as we are adding 1 it will be 1/something.\n",
    "                word_count = self.classes_info[index][0].get(word,0)+1\n",
    "                \n",
    "                \n",
    "                word_proba = word_count/float(self.classes_info[index][2])\n",
    "                \n",
    "                # Applying Log so that it enhances the minute values,\n",
    "                # our actual way is to multiply each words probability\n",
    "                # but we are applying log so we need to sum all these \n",
    "                # log applied probabilities of each word\n",
    "                likelihood_prob[index]+=np.log(word_proba)\n",
    "                \n",
    "        post_proba = np.empty(self.classes.shape[0])\n",
    "        for index,labels in enumerate(self.classes):\n",
    "            post_proba[index] = likelihood_prob[index]+np.log(self.classes_info[index][1])\n",
    "        \n",
    "        return post_proba;\n",
    "    \n",
    "    \n",
    "    \n",
    "    def test(self,test_data):\n",
    "        '''\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        test_data -> test sentences of which we need to predict the probabilities\n",
    "        \n",
    "        \n",
    "        Functionality:\n",
    "        --------------\n",
    "        Gets the proba of each sentence w.r.t each class and gets final prediction\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        Predicted Class labels of each test Sentence\n",
    "        '''\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        for sent in test_data:\n",
    "            \n",
    "            cleaned_sent = preprocess_string(sent)\n",
    "            \n",
    "            post_proba = self.getPosteriorProba(cleaned_sent)\n",
    "            \n",
    "            pred.append(self.classes[np.argmax(post_proba)])\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(str_arg):\n",
    "    \n",
    "    \"\"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        str_arg: example string to be preprocessed\n",
    "        \n",
    "        What the function does?\n",
    "        -----------------------\n",
    "        Preprocess the string argument - str_arg - such that :\n",
    "        1. everything apart from letters is excluded\n",
    "        2. multiple spaces are replaced by single space\n",
    "        3. str_arg is converted to lower case \n",
    "        \n",
    "        Example:\n",
    "        --------\n",
    "        Input :  Menu is absolutely perfect,loved it!\n",
    "        Output:  ['menu', 'is', 'absolutely', 'perfect', 'loved', 'it']\n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        Preprocessed string \n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    cleaned_str=re.sub('[^a-z\\s]+',' ',str_arg,flags=re.IGNORECASE) #every char except alphabets is replaced\n",
    "    cleaned_str=re.sub('(\\s+)',' ',cleaned_str) #multiple spaces are replaced by single space\n",
    "    cleaned_str=cleaned_str.lower() #converting the cleaned string to lower case\n",
    "    \n",
    "    return cleaned_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Review Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = pd.read_sql_query(\"\"\"select * from Reviews where\n",
    "score != 3\n",
    "\"\"\",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364173, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = filtered_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"},keep=\"first\",inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "def partition(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "\n",
    "actualScore = final['Score']\n",
    "positiveNegative = actualScore.map(partition)\n",
    "final['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(final['Text'][0:80000])\n",
    "y = list(final['Score'][0:80000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data,test_data,train_labels,test_labels=train_test_split(X,y,shuffle=True,test_size=0.25,random_state=42,stratify=y)\n",
    "classes=np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb1 = NaiveBayes(np.array([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb1.train(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy:  90.31 %\n"
     ]
    }
   ],
   "source": [
    "proba_sent1=nb1.test(test_data)\n",
    "\n",
    "#accuracy\n",
    "test_acc=np.sum(proba_sent1==test_labels)/float(len(test_labels)) \n",
    "\n",
    "print (\"Test Set Accuracy: \",test_acc*100,\"%\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "-  We have created our Own Naive Bayes Classifier from Scratch using only 4 Methods\n",
    "-  Used __Amazon Reviews DataSet__ to demonstrate our Classifier\n",
    "-  Achieved __90.31%__ Accuracy with __80000__ data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
